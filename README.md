We want to drop duplicate rows from your DataFrame, Use drop_duplicates, but be mindful of the parameter, A keen reader will notice that the solution didn’t actually drop any rows, The reason is because drop_duplicates defaults to only dropping rows that match perfectly across all
columns. Under this condition, every row in our DataFrame, dataframe, is actually unique. However, often we want to consider only a subset of columns to check for duplicate rows. We can accomplish this using the subset parameter
Take a close look at the preceding output: we told drop_duplicates to only consider any two rows with the same value for Sex to be duplicates and to drop them. Now we are left with a DataFrame of only two rows: one man and one woman.
You might be asking why drop_duplicates decided to keep these two rows instead of two different rows. The answer is that drop_duplicates defaults to keeping the first occurrence of a duplicated row and dropping the rest. We can control
this behavior using the keep parameter A related method is duplicated, which returns a boolean series denoting if a row is a duplicate or not.This is a good option if you don’t want to simply drop duplicates.
